Tracking by Histogram Comparison:

My involvement in the project revolved around using histogram comparisons to track objects through a scene.  In an attempt to track the movement of multiple Gelada monkeys across an unmoving scene, I tried to utilize multiple functions of OpenCV, namely Meanshift and Camshift.  After many tries at using OpenCV's implementations with lackluster results, I decided to create a brute-force algorithm of my own, to compare and 
Meanshift and Camshift
Meanshift is a 
The OpenCV functions for Meanshift and Camshift do not have much documentation online, and all example code online is basically identical code to one another.  I first started by attempting to track a Gelada in a small, 10 second clip, using Camshift.  Camshift is an altered version of Meanshift, which incorporates a window-resizing aspect into Meanshift in order to track objects at varying distances from the camera.  While I originally thought it would be very easy to use, it quickly proved more dificult than anticipated.  The algorithm itself does not have many paramaters to change and work with, yet no matter what paramaters I used, the "tracking window" would just constantly grow larger and larger, until it filled the screen it was in. The examples I could find online all used the same exact parameters, and those parameters yielded no results for me.
After trying many different ways, I decided to move on and use the default meanshift algorithm.  Even though the tracking window for meanshift would not resize, I felt it would work well enough without resizing.  After setting up the code using the parameters that many examples online use, I found that the tracking window would drift away from the Gelata instantly.  I did a lot of research on the OpenCV implementation and tried multiple ways to make the identifier more accurate, including:
-Grayscaling the image, and then doing some morphological operations to attempt to differentiate the Gelata from the background.  This included thresholding, opening, and dilating.  This resulted in some white blobs in the areas of the monkeys, but also a lot of noise in the background that could not be expelled. In addition, the white blobs that corresponded to monkeys were unreliable from frame to frame.

A few other failed attempts included:
-Using a combination of Meanshift and Blob Tracking.  I attempted to use OpenCV's SimpleBlobDetector to detect the monkeys based on set paramaters, and then I would use those found points to create bounding boxes around the initial Geladas.  Once the bounding boxes are set, I would run Meanshift to track.  This idea worked fairly well, after much parameter tweaking with SimpleBlobDetector.  There are many usable parameters, such as concavity, size, inertia, shape, etc.  In the end, I decided not to use this implementation of finding monkeys, due to the fact that there was still a large margin of error, even after trying to tweak the parameter settings to be more accurate.  
-Using OpenCV's goodFeaturesToTrack function to detect Geladas. This method worked pretty well for what I needed.  It detected many of the areas the Geladas were in, due to the monkeys having unique keypoints compared to the rest of the setting.  There was a fair amount of noise, things like rocks and trees and grass being detected as a "good feature," but overall it did well.  I used this detection method as I worked more on Meanshift.

After much testing and work, I gave up on OpenCV's Meanshift and Camshift implementations in favor of my own.  While I could not manage to get their implementations of tracking by histogram comparison to work, that did not give me a real indication on the usability of histogram comparison. So, I created a brute-force algorithm to track an object.  The algorithm is as follows:

-First, a list of points are passed in. These points correspond to the center pixel of the object to track in the image.  This can be supplemented by another list, containing the preferred size of the window for each object (default in my program is 60 pixels).  In my implementation, I use points gathered through Avi's implementation of a Background Subtractor.  He uses connected components to find each object in the scene that is not background, and then finds their center pixel, and creates a list of them.  
-Next, the data is used to create multiple instances of the class Monkey.  This class holds the data of: the center pixel, the "target histogram" (as explained later), and the size of the window used.
-On each frame of the window, the brute-force histogram comparison is run for each object.  A pseudocode explanation is as follows:
-For each object, find the pixel in a specified radius around the center pixel which best compares to the original target histogram.  This "target histogram" is the histogram created at the beginning of the program, which is the our first record of the object.  The search radius is alterable, however I found the best radius to use is 7 pixels, and use that in my demos.  The pixel that best compares to the target histogram is then set as the center pixel of the Monkey object, and the next computation is done. This happens for each frame of the video until the end.

